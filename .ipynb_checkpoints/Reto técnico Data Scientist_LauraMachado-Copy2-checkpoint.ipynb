{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Ha disminuido la concetración de gases tras las restricciones de Madrid Central? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Comentar la celda siguiente para ver las lineas de codigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"madrid_central.png\" style=\"float:right; width: 300px\"></img>\n",
    "El Ayuntamiento de Madrid pone a disposición del ciudadano un catálogo de datos abiertos sobre la ciudad madrileña. \n",
    "\n",
    "Utilizando los datos referentes a la [Calidad del Aire](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=f3c0f7d512273410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default)  queremos estudiar si tras las restricciones de tráfico llevadas a cabo en Madrid Central realmente ha disminuido la concentración de Dióxido de Nitrógeno (NO2).\n",
    "\n",
    "Para ello queremos analizar cómo ha variado la presencia de NO2 en las mediciones realizadas por las estaciones de calidad del aire dentro de Madrid Central, en torno a la fecha en la que se activaron por primera vez las restricciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que Madrid Central entró en vigor el **30 de Noviembre de 2018**, genera el dataset de partida a través de los datos que facilita el Ayuntamiento de Madrid: [Calidad del aire. Datos horarios años 2001 a 2021](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=f3c0f7d512273410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default)\n",
    "\n",
    "El dataset debe tener en cuenta las siguientes consideraciones:\n",
    "* nos interesa la zona de Madrid Central, por lo que, sólo debe contener información de aquellas estaciones que se ubiquen dentro de este área. Para este punto puedes apoyarte en los ficheros adicionales de la carpeta `Estaciones`.\n",
    "* nuestro análisis está centrado en el Dióxido de Nitrógeno, pero también queremos ver la relación con otros gases como: Monóxido de Carbono (CO), Monóxido de Nitrógeno (NO) y Óxidos de Nitrógeno (NOx). Así que podemos reducir el dataset a estas magnitudes.\n",
    "* partimos del dato diario a nivel horario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto! Vamos a cargar los ficheros que se encuentran en el link [Calidad del Aire](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=f3c0f7d512273410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default) en un diccionario organizado por año y mes llamado `downloaded` para poder inspeccionarlos.\n",
    "El diccionario tendra la estructura {`2001`: {`1`: `<df con datos de enero del 2001>`, `2`: `<df de febrero del 2001>`, `...`, `12`: `<df con datos de dic del  2001>`}, `2002`: {`<idem>`}, `...`, `2023`: {`<idem>`}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como los archivos descargados tienen una estructura de la nomenclatura similar, \n",
    "# podemos definir un bucle para que vaya inspeccionando carpeta carpeta y añadiendo cada archivo a una tabla \n",
    "\n",
    "import glob\n",
    "downloaded = {}\n",
    "\n",
    "# Define un diccionario donde cada abreviatura de mes se puede relacionar con un entero\n",
    "month_dict = {'ene': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'ago': 8, \n",
    "               'sep': 9, 'oct': 10, 'nov': 11, 'dic': 12}\n",
    "\n",
    "# El bucle:\n",
    "for year in range(2001, 2024):\n",
    "    head_folder_name = 'downloaded/'\n",
    "    sub_folder_name = 'Anio' + str(year) +'/'\n",
    "    sub_dir = head_folder_name + sub_folder_name\n",
    "    \n",
    "    # Initialise a dict that is going to store all of the month data in a given year\n",
    "    all_months = {}\n",
    "    for month in month_dict.keys():\n",
    "        \n",
    "        month_no = month_dict[month]\n",
    "        path = sub_dir + '*' + month + '*.csv'\n",
    "#         df_name = str(year) + '_' + str(month_dict[month])\n",
    "        files = glob.glob(path)\n",
    "        if files:  # check if the list is not empty\n",
    "            month_data = pd.read_csv(files[0], encoding='utf-8', delimiter=';')\n",
    "            all_months[month_no] = month_data\n",
    "    downloaded[year] = all_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionando los dataframes, podemos ver que todos tienen una columna para el año, el mes y el dia. Por lo tanto, podemos pasar a utilizar el meto `append` directamente, el cual generara un nuevo dataframe que guardaremos en la variable `combinado`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_yearly = []\n",
    "for year, year_dict in downloaded.items():\n",
    "    current_year = pd.concat(year_dict.values())\n",
    "    list_yearly.append(current_year)\n",
    "combinado = pd.concat(list_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "combinado[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar también un análisis del dataframe, para asegurarnos de que las variables categóricas y las numerales son correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinado.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el fichero `estaciones`\n",
    "Este df contiene únicamente datos de Madrid Centro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones = pd.read_csv('Estaciones/estaciones.csv', encoding='latin1', on_bad_lines='skip', delimiter=';');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo tiene una fila corrupta - c/Jupiter. Hemos añadido un parámetro on_bad_lines = 'skip' en el método read_csv para saltar las líneas que generan un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducimos la df `combinado` a los resultados de Madrid Central utilizando la df `estaciones`.\n",
    "Vemos que los dos dataframes tienen una columna en común:\n",
    "* La columna **CODIGO_CORTO** de `estaciones`, y\n",
    "* La columna **ESTACION** de `combinado`.\n",
    "Para ello, generamos una máscara y se la aplicamos a `combinado`, generando una nueva df llamada `central`.\n",
    "* Habíamos eliminado el récord de la c/Júpiter - sin embargo, por inspección visual, se puede ver que el código de esa estación era `27`, así que lo añadimos manualmente. Los códigos de la columna **CODIGO_CORTO**, junto con el número `27` se guardan en una serie llamada `manual`. Esto no es sostenible para dataframes grandes pero en esta instancia, `estaciones` es un fichero pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(estaciones['CODIGO_CORTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos el 27 a la Series para hacer la mascara\n",
    "original = estaciones['CODIGO_CORTO']\n",
    "\n",
    "added = pd.Series([27])\n",
    "\n",
    "manual = pd.concat([original, added])\n",
    "\n",
    "# Definimos la máscara\n",
    "mascara = combinado['ESTACION'].isin(manual)\n",
    "\n",
    "# Aplicamos la máscara\n",
    "central = combinado[mascara]\n",
    "central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluso nos podemos asegurar de que los códigos en la columna ESTACION de la df `central` solo contienen los valores\n",
    "# de la columna `estaciones`:\n",
    "\n",
    "series1 = estaciones['CODIGO_CORTO']\n",
    "\n",
    "series2 = central['ESTACION']\n",
    "\n",
    "for i in series1:\n",
    "    if i not in series2:\n",
    "        print('error')\n",
    "# Si esta celda no imprime nada, entonces hemos sido exitosos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiamos el dataframe `central`.\n",
    "#### 1. Nos dehacemos de columnas que no traen informacion nueva:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que las columnas 'PROVINCIA' y 'MUNICIPIO' no proveen ninguna información nueva. Nos aseguramos: Si el output siguiente es 1.0 para un único valor, esas columnas no contienen información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central['PROVINCIA'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central['MUNICIPIO'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos dehacemos de ellas, junto con **PUNTO_MUESTREO**, que es una concatenacion de otras columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central = central.drop('PROVINCIA', axis = 1)\n",
    "central = central.drop('MUNICIPIO', axis = 1)\n",
    "central = central.drop('PUNTO_MUESTREO', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Eliminamos las magnitudes que no nos interesan\n",
    "Según la descripcion del problema, nos enfocamos en:\n",
    "* Dióxido de Nitrógeno\n",
    "* Monóxido de Carbono (CO)\n",
    "* Monóxido de Nitrógeno (NO)\n",
    "* Óxidos de Nitrógeno (NOx)\n",
    "\n",
    "De acuerdo con el **ANEXO II** del diccionario de datos en [la web](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf) , estas substancias se corresponden con lo siguientes numerales de la columna  **MAGNITUD**:\n",
    "\n",
    "* NO2 <=> `08`\n",
    "* CO <=> `06`\n",
    "* NO <=> `07`\n",
    "* NOx <=> `12`\n",
    "\n",
    "Guardaré estos valores en una lista llamada `magnitudes_importantes` y eliminaré las filas que no las contengan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la lista cn los índices correctos\n",
    "magnitudes_importantes = [8, 6, 7, 12]\n",
    "\n",
    "# Modificamos el df `central`\n",
    "\n",
    "central = central[central['MAGNITUD'].isin(magnitudes_importantes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Eliminar los datos no validados:\n",
    "Según el diccionario de datos publicado en [la web](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf), solo las mediciones que contienen una V en la columna siguiente.\n",
    "Quiero analizar si hay días específicos en los que las mediciones no fueron válidas.\n",
    "\n",
    "\n",
    "##### 3.1. Investigar todos los valores de las columnas de validación\n",
    "Como queremos eliminar filas en dependencia de los valores en la columna de validación, primero quiero investigar cual es el rango de esos valores.\n",
    "\n",
    "Voy a comenzar definiendo dos listas: `horas` y `validaciones`, que contendrán los títulos de las respectivas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validaciones = ['V' + str(i).zfill(2) for i in range(1, 25)]\n",
    "\n",
    "print('La lista llamada validaciones:', validaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a user la lista `validaciones` para ver si hay otros valores en las columnas de validación `V01`, `V02`, etc a parte de N o V. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_dict = {}\n",
    "for column in validaciones:\n",
    "    value_counts = central[column].value_counts(dropna=False)\n",
    "    value_counts_dict[column] = value_counts\n",
    "\n",
    "value_counts_df = pd.DataFrame(value_counts_dict)\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos confirmado que los valores de validación son 'N' o 'V', podemos asegurarnos de que el siguiente código, cuando borre las filas que no contengan 'V', estaremos produciendo un nuevo data frame, al que llamaremos final, que solo contenga los datos validados.\n",
    "Eliminaremos estas mediciones sin validar, guardando el dataframe bajo una nueva variable: final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "mask = central[validaciones].ne('V').any(axis=1)\n",
    "final = central[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que la operación ha sido exitosa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_dict_final = {}\n",
    "for column in validaciones:\n",
    "    value_counts = final[column].value_counts(dropna=False)\n",
    "    value_counts_dict_final[column] = value_counts\n",
    "\n",
    "value_counts_df_final = pd.DataFrame(value_counts_dict_final)\n",
    "value_counts_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y nos dehacemos de todas las columnas de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in validaciones:\n",
    "    final = final.drop(column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Creamos una columna con valores medios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una columna en el df `final` que calcule la media diaria por cade fila, tomando los valores de **H01** a **H24** para computar la media.\n",
    "Despues, como en este ejercicio no vamos a usar los datos horarios, podemos generar un df mas ligero al deshacernos de las columnas **H01**-**H24** y solo conservar la `media_diaria`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la lista `horas` que contiene los titulos de las columnas H01 a H24\n",
    "# La logica es la misma que usamos para la lista `validaciones`.\n",
    "\n",
    "horas = ['H' + str(i).zfill(2) for i in range(1, 25)]\n",
    "\n",
    "# Despues, tomamos la media:\n",
    "final['media_diaria'] = final[horas].mean(axis = 1)\n",
    "\n",
    "# Eliminamos las columnas horarias\n",
    "final = final.drop(horas, axis = 1)\n",
    "\n",
    "# Visualizamos el df:\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Combinamos las columnas de fecha en un objeto `datetime` llamado `fecha` que substituirá las columnas `ANO`, `MES` y `DIA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['date_str'] = final['ANO'].astype(str) + '-' + final['MES'].astype(str) + '-' + final['DIA'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['fecha'] = pd.to_datetime(final['date_str'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(['date_str', 'ANO', 'MES', 'DIA'], axis = 1)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio del efecto inmediato de Madrid Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar los efectos inmediatos de las restricciones, empezamos por representar de manera **gráfica** la serie temporal de **Dióxido de Nitrógeno**. Marca en la gráfica la entrada en vigor de la normativa de Madrid Central para facilitar el estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dióxido de nitrógeno tiene el código `8` en la columna **MAGNITUD**.\n",
    "Vamos a generar el df `NO2` que contenga solamente estas mediciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_NO2 = final['MAGNITUD'] == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_NO2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO2_df = final[mask_NO2]\n",
    "NO2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO2_df = NO2_df.sort_values('fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, calculamos el resultado medio de todas las estaciones por fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_estaciones = NO2_df.groupby('fecha')['media_diaria'].mean().reset_index()\n",
    "media_estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='fecha', y='media_diaria', data = media_estaciones)\n",
    "\n",
    "# Definimos los ejes\n",
    "plt.xlabel('Fecha')\n",
    "ylabel = 'Dióxido de Nitrógeno/ ' + r'$\\mu g/m^3$'\n",
    "plt.ylabel(ylabel)\n",
    "\n",
    "# Guardamos el inicio de la normativa y lo convertimos en datetime\n",
    "normativa = '2018-11-30'\n",
    "\n",
    "highlight_date = pd.to_datetime(normativa)\n",
    "\n",
    "# Anadimos una raya vertical violeta en la fecha de la normativa\n",
    "plt.axvline(x=highlight_date, color='blueviolet', linestyle='--')  \n",
    "\n",
    "plt.text(0.5, -0.2, 'Figura 1: Evolución temporal de la concentración de dióxido de nitrógeno en el aire de madrid central.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.25,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar mejor los resultados, representa también **cómo varia la emisión media diaria de este gas frente al año anterior** a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Extraemos el año de la columna `fecha`\n",
    "NO2_df['Year'] = NO2_df['fecha'].dt.year\n",
    "\n",
    "# Tomamos la media por año\n",
    "media_anual = NO2_df.groupby('Year')['media_diaria'].mean()\n",
    "\n",
    "\n",
    "# Para poder representar tanto la media anual como una línea vertical marcando \n",
    "# el inicio de la normativa, vamos a crear subgráficas \n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(media_anual.index, media_anual.values, marker='o', label='Media Anual')\n",
    "ax1.set_xlabel('Año')\n",
    "ax1.set_ylabel('Concentración Media Anual de ' + ylabel )\n",
    "ax1.set_title('Cambios de año en año')\n",
    "ax1.grid(True)\n",
    "\n",
    "#  Añadimos una línea vertical roja de guiones para la fecha 30/11/2018\n",
    "ax1.axvline(pd.to_datetime('2018-11-30').year, color='blueviolet', linestyle='--', label='Comienzo Normativa')\n",
    "ax1.legend()\n",
    "\n",
    "# Leyendas\n",
    "plt.text(0.5, -0.2, 'Figura 2: Evolución anual de la concentración media de dióxido de nitrógeno en el aire de madrid central.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.25,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué conclusiones sacas tras este primer análisis?** \n",
    "* ¿Realmente ha disminuido la concentración del NO2 tras la aplicación de Madrid Central? \n",
    "* ¿Utilizarías algún otro gráfico para mostrar los resultados? En caso afirmativo, muéstralo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusiones del Primer Análisis\n",
    "* En efecto, la cantidad media de dióxido de nitrógeno está en decremento desde el año dos mil. \n",
    "* Actualmente se encuentra en los valores mínimos reportados desde el comienzo del milenio. \n",
    "\n",
    "* La media anual nos ayuda bastante más que la cantidad neta de dióxido de nitrógeno para poder evaluar el efecto de la entrada en vigor de la normativa de restricción del tráfico a finales del 2018. \n",
    "* En la Figura 1, donde hemos representado el resultado de la medición de dióxido de nitrógeno a través del tiempo, se puede observar que aparenta un pequeño descenso de la cantidad media de dióxido de nitrógeno.\n",
    "* Sin embargo, esto se confirma de forma más concluyente con la gráfica de la Figura 2, en la cual se puede ver un descenso a lo largo del tiempo de la cantidad media anual de dióxido de nitrógeno.\n",
    "\n",
    "* Algo interesante que se puede mencionar en este punto es que, según la Figura 2, la cantidad de dióxido de nitrógeno media está en descenso desde el año 2000, incluso **antes** de entrar en vigor la normativa de restricción del tráfico del 2018.\n",
    "* Parte de este decremento se puede adjudicar a la implementación de una serie de estándares de emisión llamados los estándares EURO que implementó la Unión Europea.\n",
    "\n",
    "* Estos estándares se han estado implementando en iteraciones, cada una más estricta que la anterior. El estándar [EURO 4](https://www.europarl.europa.eu/registre/docs_autres_institutions/commission_europeenne/sec/2005/1745/COM_SEC(2005)1745_EN.pdf), puesto en marcha en el 2005, redujo de manera significativa las emisiones de dióxido de óxidos de nitrógeno permitidas por los vehículos diesel comparados con el estándar anterior europeo.\n",
    "\n",
    "* En la Figura 2 se puede observar claramente que es en esta fecha en 2005 cuando la mayor caída de concentración empieza a ocurrir.\n",
    "\n",
    "* Además, en el 2008, la Unión Europea implementó la directiva de la calidad del aire [Cleaner Air for Europe](https://eur-lex.europa.eu/EN/legal-content/summary/cleaner-air-for-europe.html) que restringía de forma legal los límites para los mayores contaminantes del aire, incluyendo el dióxido de nitrógeno.\n",
    "\n",
    "* Como esta era una normativa legal, todos los países miembros de la Unión Europea incluyendo España tuvieron que adherirse.\n",
    "En la Figura 2 podemos ver como en el 2008 se continúa un descenso en la cantidad de dióxido de nitrógeno en el aire, lo cual evidencia la efectividad de estas políticas.\n",
    "\n",
    "* Hay otros factores que suman en el esfuerzo contra los contaminantes en el aire.\n",
    "\n",
    "* Por ejemplo, desde el 2014,  el uso de los coches diésel fue disminuyendo en España, según reporta [El Periódico](https://www.elperiodico.com/es/economia/20160506/ventas-coches-diesel-gasoleo-gasolina-electricos-hibridos-5112843).\n",
    "\n",
    "![Gráfica de porcentaje de cuota de mercado de los vehículos diésel en España desde el 1990 hasta el 2015 en la cual se puede observar que la cantidad de vehículos diésel disminuye desde el 2014.](images/diesel_esp.jpg)\n",
    "\n",
    "* Además, la transición a nuevas formas de energía más limpias también ha ayudado a reducir el porcentaje de combustibles derivados del petróleo en uso. Según el blog del canal Economia3, únicamente la energía eólica ha incrementado en un 10%, desde el 2004.\n",
    "\n",
    "![Gráfica de porcentaje de De producción de energía eólica desde el 2004 hasta hoy en la que se puede ver un incremento anual de año a año.](images/renovables.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto al resto de gases que comentábamos al inicio: CO, NO y NOx, **¿ha habido un descenso a nivel anual en la emisión media de los gases entre los años 2018 y 2021?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['MAGNITUD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el nuevo df con las cuatro magnitudes a parte de NO2: CO, NO y NOx \n",
    "# y la media tomada en todas las estaciones acada dia.\n",
    "\n",
    "final_media_estaciones = final.groupby(['fecha', 'MAGNITUD'])['media_diaria'].mean().reset_index()\n",
    "final_media_estaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por referencia, recordamos la leyenda de la columna **MAGNITUD**:\n",
    "* NO2 <=> `08`\n",
    "* CO <=> `06`\n",
    "* NO <=> `07`\n",
    "* NOx <=> `12`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos esos valores numericos por el nombre de cada molecula:\n",
    "final_media_estaciones['MAGNITUD'] = final_media_estaciones['MAGNITUD'].replace({\n",
    "    8: 'Dióxido de Nitrógeno (NO2)',\n",
    "    6: 'Monóxido de Carbono (CO)',\n",
    "    7: 'Monóxido de Nitrógeno (NO)',\n",
    "    12: 'Óxidos de Nitrógeno (NOx)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_media_estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.lineplot(x='fecha', y='media_diaria', hue='MAGNITUD', data=final_media_estaciones)\n",
    "\n",
    "# Añadimos una raya vertical para marcar el comienzo de la puesta en vigencia de la normativa\n",
    "plt.axvline(pd.to_datetime('2018-11-30'), color='blueviolet', linestyle='--')\n",
    "\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Concentración Media Diaria de Cada Substancia en ' r'$\\mu g/m^3$')\n",
    "\n",
    "# Creamos una instancia line2D para la leyenda\n",
    "violet_line = mlines.Line2D([], [], color='blueviolet', linestyle='--', markersize=15, label='30 Nov 2018')\n",
    "\n",
    "# Obtenemos las handles y etiquetas \n",
    "handles, labels = plot.get_legend_handles_labels()\n",
    "\n",
    "# Añadimos una línea vertical a las handles y añadimos su etiqueta a las demás\n",
    "handles.append(violet_line)\n",
    "labels.append('30 Nov 2018')\n",
    "\n",
    "# Set the new legend\n",
    "plt.legend(handles=handles, labels=labels, title='MAGNITUD', loc='best')\n",
    "\n",
    "# Leyenda de Imagen\n",
    "plt.text(0.5, -0.1, 'Figura 3: Evolución anual de la concentración media de (1) monóxido de carbono (azul), (2) monóxido de nitrógeno (naranja) (3) dióxido de nitrógeno (verde) .',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.15, 'y (4) óxidos de nitrógeno (rojo) en el aire de madrid central entre 2018 y 2021.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.2,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Rango de tiempo\n",
    "plt.xlim([pd.to_datetime('2018-01-01'), pd.to_datetime('2021-12-31')])\n",
    "\n",
    "# Escala vertical\n",
    "plt.ylim(-1, 400)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las fluctuaciones por mes del año de los óxidos de nitrógeno oscurecen las demás. Los datos de monóxido de carbono no están normalizados y, por lo tanto, en la misma gráfica que los demás, muestran un cambio imperceptible.\n",
    "\n",
    "Para llevar a cabo la normalización de las cuatro substancias vamos a aplicar la normalización tipo *Z-score* para cada magnitud de forma separada. Este método transforma los datos para que tengan una media de 0 y una desviación estándar de 1,  facilitando así poder comparar tendencias que ocurren en diferentes escalas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Aplicamos Normalización z-score a cada MAGNITUD\n",
    "final_media_estaciones['z-score'] = final_media_estaciones.groupby('MAGNITUD')['media_diaria'].transform(zscore)\n",
    "final_media_estaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar la superposición de las gráficas y facilitar la resolución de detalles, vamos a aplicar un método de remuestreo, creando un nuevo dataframe llamado `remuestreado`. **Así representaremos únicamente un dato mensual.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remuestreo:\n",
    "remuestreado = final_media_estaciones.set_index('fecha').groupby('MAGNITUD').resample('M').mean().reset_index()\n",
    "\n",
    "# Creamos gráfica\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.lineplot(x='fecha', y='z-score', hue='MAGNITUD', data=remuestreado)\n",
    "\n",
    "# for i in range(len(plot.lines)):\n",
    "#     plot.lines[i].set_linestyle(\"--\")\n",
    "    \n",
    "# Añadimos una línea vertical \n",
    "plt.axvline(pd.to_datetime('2018-11-30'), color='blueviolet', linestyle='--')\n",
    "\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Concentración Media Diaria Normalizada de Cada Substancia en ' r'$\\mu g/m^3$')\n",
    "\n",
    "# Creamos una instancia Line2D instance para la leyenda \n",
    "violet_line = mlines.Line2D([], [], color='blueviolet', linestyle='--', markersize=15, label='30 Nov 2018')\n",
    "\n",
    "# Obtenemos las handles y etiquetas \n",
    "handles, labels = plot.get_legend_handles_labels()\n",
    "\n",
    "# Añadimos una línea vertical a las handles y añadimos su etiqueta a las demás\n",
    "handles.append(violet_line)\n",
    "labels.append('30 Nov 2018')\n",
    "\n",
    "# Leyenda de Imagen\n",
    "plt.legend(handles=handles, labels=labels, title='MAGNITUD', loc='best')\n",
    "\n",
    "plt.text(0.5, -0.1, 'Figura 5: Evolución anual de la concentración media de (1) monóxido de carbono (azul), (2) monóxido de nitrógeno (naranja) (3) dióxido de nitrógeno (verde) .',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.15, 'y (4) óxidos de nitrógeno (rojo) en el aire de madrid central entre 2018 y 2021.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.2,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Rango de tiempo\n",
    "plt.xlim([pd.to_datetime('2018-01-01'), pd.to_datetime('2021-12-31')])\n",
    "plt.ylim(-2, 1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez normalizados los datos, podemos ver que la amplitud de las oscilaciones anuales parece disminuir de año en año. Sin embargo, estas oscilaciones dificultan la precisión de este descenso, si existe.\n",
    "\n",
    "Me pregunto si cogiendo la media anual - igual que hicimos en la Figura 2 - nos ayudaría a ver estas tendencias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos gráfica\n",
    "fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Hacemos un bucle sobre los valores únicos de la columna MAGNITUD\n",
    "for magnitud in final_media_estaciones['MAGNITUD'].unique():\n",
    "\n",
    "    # Creamos un dataframe del subconjunto de filas que tienen la magnitud actual \n",
    "    subset = final_media_estaciones[final_media_estaciones['MAGNITUD'] == magnitud].copy()\n",
    "    \n",
    "    # Calculamos una media anual para el subconjunto\n",
    "    subset['fecha'] = pd.to_datetime(subset['fecha'])\n",
    "    media_anual = subset.resample('Y', on='fecha')['z-score'].mean()\n",
    "\n",
    "    # Graficamos la línea de dispersión para el subconjunto \n",
    "    ax1.plot(media_anual.index.year, media_anual.values, marker='o', label=f'Media Anual {magnitud}')\n",
    "\n",
    "# Establecemos las etiquetas y el título\n",
    "ax1.set_xlabel('Año')\n",
    "ax1.set_ylabel('Concentración Media Anual Normalizada de Cada Substancia en ' r'$\\mu g/m^3$')\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "# Añadimos la línea vertical que marca el comienzo de la normativa\n",
    "ax1.axvline(pd.to_datetime('2018-11-30').year, color='blueviolet', linestyle='--', label='Comienzo Normativa Noviembre 2018')\n",
    "ax1.legend()\n",
    "\n",
    "# Leyenda de Imagen\n",
    "plt.text(0.5, -0.1, 'Figura 6: Evolución de la media anual normalizada de la concentración media de (1) monóxido de carbono'\n",
    "         '(azul), (2) monóxido de nitrógeno (naranja) (3) dióxido de nitrógeno (verde).',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.15, 'y (4) óxidos de nitrógeno (rojo) en el aire de madrid central desde el año 2000.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.2,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Rango de tiempo\n",
    "plt.xlim([2000, 2023])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restringiendo esta gráfica entre el 2018 y 2021:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos gráfica\n",
    "fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Hacemos un bucle sobre los valores únicos de la columna MAGNITUD\n",
    "for magnitud in final_media_estaciones['MAGNITUD'].unique():\n",
    "\n",
    "    # Creamos un dataframe del subconjunto de filas que tienen la magnitud actual \n",
    "    subset = final_media_estaciones[final_media_estaciones['MAGNITUD'] == magnitud].copy()\n",
    "    \n",
    "    # Calculamos una media anual para el subconjunto\n",
    "    subset['fecha'] = pd.to_datetime(subset['fecha'])\n",
    "    media_anual = subset.resample('Y', on='fecha')['z-score'].mean()\n",
    "\n",
    "    # Graficamos la línea de dispersión para el subconjunto \n",
    "    ax1.plot(media_anual.index.year, media_anual.values, marker='o', label=f'Media Anual {magnitud}')\n",
    "\n",
    "# Establecemos las etiquetas y el título\n",
    "ax1.set_xlabel('Año')\n",
    "ax1.set_ylabel('Concentración Media Anual Normalizada de Cada Substancia en ' r'$\\mu g/m^3$')\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "# Añadimos la línea vertical que marca el comienzo de la normativa\n",
    "ax1.axvline(pd.to_datetime('2018-11-30').year, color='blueviolet', linestyle='--', label='Comienzo Normativa Noviembre 2018')\n",
    "ax1.legend()\n",
    "\n",
    "# Leyenda de Imagen\n",
    "plt.text(0.5, -0.1, 'Figura 7: Evolución de la media anual normalizada de la concentración media de (1) monóxido de carbono (azul), (2) monóxido de nitrógeno (naranja) (3) dióxido de nitrógeno (verde) .',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.15, 'y (4) óxidos de nitrógeno (rojo) en el aire de madrid central entre el 2018 y 2021.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.2,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Rango de tiempo\n",
    "plt.xlim([2017.8, 2022]) #Empezamos con un decimal porque, si no, la linea vertical se aproxima a 2019.\n",
    "\n",
    "# Escala vertical\n",
    "plt.ylim(-1, 0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusiones\n",
    "* Efectivamente, habiendo tomado la media anual de cada sustancia a través del tiempo se revela la disminución de concentración desde el año 2000 hasta el presente. \n",
    "* Esta progresión ocurre de manera gradual.\n",
    "* Se puede observar que, después del 2005, cuando la primera iniciativa europea de control de partículas de calidad del aire fue implementada, como hemos detallado en el ejercicio anterior, las cantidades bajaron precipitadamente. \n",
    "* Es difícil atribuir la disminución en las concentraciones medias a la implementación de la normativa de restricción de tráfico en Madrid central en 2018, ya que la disminución posterior a este punto en el tiempo está en sincronía con la trayectoria anterior a la normativa.\n",
    "* Una nota que debemos especificar en este punto es que los datos validados de monóxido de carbono eran menos de la mitad del equivalente en las demás sustancias (ver output de celda 42). este hecho coma no solo revela la necesidad de mejorar tanto la Adquisición De medidas como la validación de esta sustancia,  sino que también indica que la verosimilitud de esta curva de datos (azul) en la Figura 6 puede ser menor que la de las otras sustancias. \n",
    "* Finalmente, queremos dejar saber al lector que nota un incremento en la concentración de todas las sustancias en el 2023 en la Figura 7,  que hoy, a Julio de  ese mismo año,  la media ha sido tomada sobre los datos existentes; es decir, de enero a mayo. Por lo tanto, la bajada de verano no ha sucedido, y el valor medio “anual” representado es artificialmente alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio del efecto de las precipitaciones sobre las emisiones de estos gases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta variación puede deberse a un aumento/disminución de las precipitaciones en esos años. Por lo que, sería interesante analizar el efecto de las precipitaciones, para ello disponemos de las precipitaciones a lo largo de los años 2018 y 2019 en Madrid, en el fichero `historico.clima.xlsx`.\n",
    "\n",
    "**¿Explica el comportamiento anual de las precipicationes la variación en los niveles de gases bajo estudio o podemos atribuir dicho efecto a la implementación de Madrid central?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitaciones = pd.read_excel('historico-clima.xlsx', parse_dates = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla ha sido correctamente leida con una columna con objetos `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitaciones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_con_precipitaciones = final_media_estaciones.merge(precipitaciones, left_on='fecha', right_on='timestamp', how='inner')\n",
    "final_con_precipitaciones = final_con_precipitaciones.drop('timestamp', axis = 1)\n",
    "final_con_precipitaciones['Precipitation z-score'] = zscore(final_con_precipitaciones['Madrid Precipitation Total'])\n",
    "final_con_precipitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear otra gráfica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remuestreo:\n",
    "remuestreado = final_con_precipitaciones.set_index('fecha').groupby('MAGNITUD').resample('M').mean().reset_index()\n",
    "\n",
    "# Tambien remuestreamos los datos de Precipitation para agilzar el proceso:\n",
    "precipitation_remuestreado = final_con_precipitaciones.set_index('fecha').resample('M')['Precipitation z-score'].mean().reset_index()\n",
    "\n",
    "# Creamos gráfica\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.lineplot(x='fecha', y='z-score', hue='MAGNITUD', data=remuestreado)\n",
    "\n",
    "# Add precipitation data to the same plot\n",
    "sns.lineplot(x='fecha', y='Precipitation z-score', data=precipitation_remuestreado, color='purple', label='Precipitacion Normalizada')\n",
    "\n",
    "# Añadimos una línea vertical \n",
    "plt.axvline(pd.to_datetime('2018-11-30'), color='blueviolet', linestyle='--')\n",
    "\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Concentración Media Diaria Normalizada de Cada Substancia en '+ r'$\\mu g/m^3$')\n",
    "\n",
    "# Creamos una instancia Line2D instance para la leyenda \n",
    "violet_line = mlines.Line2D([], [], color='blueviolet', linestyle='--', markersize=15, label='30 Nov 2018')\n",
    "\n",
    "# Obtenemos las handles y etiquetas \n",
    "handles, labels = plot.get_legend_handles_labels()\n",
    "\n",
    "# Añadimos una línea vertical a las handles y añadimos su etiqueta a las demás\n",
    "handles.append(violet_line)\n",
    "labels.append('30 Nov 2018')\n",
    "\n",
    "# Leyenda de Imagen\n",
    "plt.legend(handles=handles, labels=labels, title='MAGNITUD', loc='best')\n",
    "\n",
    "plt.text(0.5, -0.1, 'Figura 8: Evolución de la concentración media de (1) monóxido de carbono'\n",
    "         ' (azul), (2) monóxido de nitrógeno (naranja) (3) dióxido de nitrógeno (verde).',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.15, 'y (4) óxidos de nitrógeno (rojo) en el aire de madrid central entre 2018 y 2019. La precipitación normalizada es la curva morada.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.2,' La línea violeta vertical marca el 30 de noviembre de 2018, cuando se puso en marcha la normativa' \n",
    "         ' de restricciones de tráfico.', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Rango de tiempo\n",
    "plt.xlim([pd.to_datetime('2018-01-01'), pd.to_datetime('2019-12-31')])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En abril del año 2018, se puede observar un incremento de las precipitaciones en la Figura 8, tras el cual las concentraciones normalizadas de todas las sustancias disminuyen en picado aceleradamente. \n",
    "* Sin embargo , en noviembre del 2018, se vuelve a observar un “valle” en las gráficas de las concentraciones de la sustancias mientras hay un aumento de las precipitaciones. \n",
    "* Después de esta fecha, se observa una disminución de la concentración normalizada de todas las sustancias en el aire. No obstante, esta es la etapa posterior a la entrada en vigencia de la normativa de calidad del aire en Madrid central, así que es complicado relacionar esta disminución con la presencia o falta de altas precipitaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué usos de Machine Learning verías aplicables a este conjunto de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si hubiera más datos de precipitación disponibles, que abarcaran un rango temporal más amplio, sería interesante utilizar una regresión linear para calcular la concentración media de las cuatro substancias basado en los cambios en la precipitación total. \n",
    "* Dado que las concentraciones de cada una de las cuatro substancias existen en escalas bastante distintas, podemos pensar en dos soluciones diferentes:\n",
    "\n",
    "    * Entrenar a un único modelo, y hacer que la target variable sea el Z-score medio de las concentraciones de las cuatro substancias. Este modelo no tendría un poder cuantitativo, pero sería útil como una guía visual en el tiempo. \n",
    "    * La otra solución sería crear cuatro modelos distintos entrenados en datos de cada una de las cuatro sustancias que tenemos en nuestra base de datos. Este modelo tendría un poder cuantitativo, ya que no tendríamos que normalizar los datos a priori. \n",
    "\n",
    "* Deberíamos también concentrarnos únicamente en la en una de las dos: o la etapa anterior a la entrada en vigencia de la normativa, o la etapa posterior a ella. No deberíamos crear un modelo que mezclara datos de las dos, ya que no son comparables debido a factores externos.\n",
    "* Con vistas a cuál de los dos rangos de datos serían más interesantes para generar un modelo que pueda tener una aplicación útil para un usuario, deberíamos enfocarnos en los datos de precipitación posteriores a la entrada en vigencia a la normativa, ya que ellos nos permitirían predecir la concentración en el aire en el futuro basados en la situación actual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podrías usar uno de esos modelos de Machine Learning para **predecir las emisiones de NO2 durante la siguiente semana** al fin de los datos de tu dataset (agregado a nivel día)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada esta tarea, vamos a utilizar los datos tanto de precipitación como de dióxido de nitrógeno después de la entrada en vigor de la normativa de calidad del aire en Madrid central. Así, generaremos una nueva tabla, llamada `precip_no2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aislamos los valores de dióxido de nitrógeno de la tabla final\n",
    "mascara = final_con_precipitaciones['MAGNITUD'] == 'Dióxido de Nitrógeno (NO2)'\n",
    "precip_no2 = final_con_precipitaciones[mascara]\n",
    "\n",
    "# Eliminamos las columnas que ya no traen ningún valor \n",
    "precip_no2 = precip_no2.drop(['MAGNITUD', 'z-score', 'Precipitation z-score'], axis = 1)\n",
    "\n",
    "# Restringimos los datos en el tiempo a la etapa posterior a la entrada en \n",
    "# vigor de la normativa\n",
    "normativa = datetime.strptime('2018-11-30', '%Y-%m-%d')\n",
    "datemask = precip_no2['fecha'] >= normativa\n",
    "precip_no2 = precip_no2[datemask]\n",
    "precip_no2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos datos de carácter temporal, no tiene sentido hacer `train/test/split`.\n",
    "En vez de ello, vamos a separar los datos manualmente. Dentro del rango para el cual tenemos datos de las precipitaciones, voy a separar el primer 70% para entrenar al modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_datos = datetime.strptime('2019-12-31', '%Y-%m-%d')\n",
    "rango = final_datos - normativa\n",
    "final_training = normativa + 0.7*rango\n",
    "print('La fecha que marca el final de los datos para entrenar al modelo es el', \n",
    "      final_training.strftime('%d/%m/%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiremos `precip_no2` en dos: `training_70`, que llegará hasta el 3 de septiembre del 2019; y `test_30`, que abarcará el resto del año 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos training\n",
    "datetime_mask_70 = precip_no2['fecha'] <= final_training\n",
    "training_70 = precip_no2[datetime_mask_70]\n",
    "# Definimos testing\n",
    "test_30 = precip_no2[~datetime_mask_70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def linear_train_and_predict(train, test):\n",
    "    X_train = np.array(train['Madrid Precipitation Total']).reshape(-1,1)\n",
    "    y_train = np.log(train['media_diaria'])\n",
    "    X_test = np.array(test['Madrid Precipitation Total']).reshape(-1,1)\n",
    "    \n",
    "    # Entrenamos al modelo \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecimos \n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    return np.exp(y_pred) # return to original scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una ventana rodante para simular la creación de un pronóstico dinámico. En nuestro caso la ventana es la tabla compuesta por los datos que están disponibles para entrenar al modelo en el momento de cada predicción. Según el tiempo avanza, la ventana se desplaza también, y continuamente estamos re-entrenando nuestro modelo con los datos más recientes para llevar a cabo predicciones sobre el periodo siguiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana_size = 30\n",
    "predicciones = []\n",
    "cutoff = int(len(precip_no2) * 0.7)\n",
    "\n",
    "for i in range(ventana_size, len(test_30)):\n",
    "    train_temp = pd.concat([training_70, test_30.iloc[:i]])  # use pandas.concat instead of append\n",
    "    test_temp = test_30.iloc[i:i+1]  # test data is a single sample from test_30\n",
    "    predicciones.append(linear_train_and_predict(train_temp, test_temp))\n",
    "\n",
    "\n",
    "# Creamos la lista de predicciones\n",
    "predicciones = [item for sublist in predicciones for item in sublist]\n",
    "# predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert test_30 and predicciones to numpy arrays for easier plot handling\n",
    "test_30_values = test_30['media_diaria'].to_numpy()\n",
    "predicciones_values = np.array(predicciones)\n",
    "\n",
    "# Trim test_30_values to match the length of predicciones_values\n",
    "test_30_values_trimmed = test_30_values[-len(predicciones_values):]\n",
    "\n",
    "# Generate index for x-axis\n",
    "index = range(0, len(test_30_values_trimmed))\n",
    "\n",
    "# Plot actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(index, test_30_values_trimmed, color='blue', label='Actual Values')\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(index, predicciones_values, color='red', linestyle='dashed', label='Predicted Values')\n",
    "\n",
    "\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('media_diaria')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.text(0.5, -0.2, 'Figura 9: Comparación de las figuras actuales (azul continuo)  y las predichas (rojo guionado) por el modelo lineal.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se puede observar que la predicción del modelo no continúa el mismo patrón que los datos reales.**\n",
    "\n",
    "Ahora podemos evaluar el rendimiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_test = np.array(test_30['media_diaria'][ventana_size:])\n",
    "print(\"Test RMSE: \", np.sqrt(mean_squared_error(y_test, predicciones)))\n",
    "print(\"Test R2 Score: \", r2_score(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación R^2 de -0.072 indica que el modelo no explica bien la variabilidad en la variable objetivo. Una puntuación R^2 de 1 significa que el modelo explica perfectamente la variabilidad, mientras que una puntuación de 0 significa que no explica la variabilidad en absoluto. Una puntuación R^2 menor a 0, como en este caso, indica que el modelo es peor que simplemente predecir la media de la variable objetivo.\n",
    "\n",
    "Para investigar si la relación entre la concentración de dióxido de nitrógeno y la precipitación es lineal, vamos a graficar las dos variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Gráfico de dispersión\n",
    "plt.scatter(precip_no2['Madrid Precipitation Total'], precip_no2['media_diaria'], alpha=0.5)\n",
    "\n",
    "# títulos de eje \n",
    "plt.xlabel('Madrid Precipitation Total (Log)')\n",
    "plt.ylabel('Concentracion de Dióxido de Nitrógeno en ' + r'$\\mu g/m^3$')\n",
    "\n",
    "plt.text(0.5, -0.2, 'Figura 10: Gráfico de dispersión de la concentración'\n",
    "         ' de dióxido de nitrógeno contra la precipitación en Madrid central en escala logarítmica.',\n",
    "         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Usamos una escala logarítmica en el eje X porque los valores de la precipitación están bastante cerca de cero \n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que **no hay una relación lineal entre las dos variables.**\n",
    "\n",
    "\n",
    "Como último intento, vamos a crear una instancia de un algoritmo de soporte de regresión de vectores (SVR) con crossvalización, a la que llamaremos `svr_train_and_predict_with_cv`.\n",
    "\n",
    "Para la regresión no lineal, SVR aplica el \"truco del kernel\", que  transforma los datos de entrada en un espacio de mayor dimensión. Esta transformación puede hacer que una relación no lineal parezca lineal en el espacio transformado, lo que permite que el algoritmo encuentre un hiperplano que se ajuste a los datos.\n",
    "\n",
    "En este caso, si efectivamente existe una relación no lineal entre la precipitación y la concentración de NO2, entonces SVR (con un kernel no lineal apropiado como la Función de Base Radial (RBF)) podría potencialmente modelar esa relación mejor que la simple regresión lineal. Sin embargo, SVR también tiene su propio conjunto de hiperparámetros, como el parámetro de regularización C y los parámetros del kernel, que deben ser ajustados adecuadamente para obtener los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def svr_train_and_predict_with_cv(train, test):\n",
    "    X_train = np.array(train['Madrid Precipitation Total']).reshape(-1,1)\n",
    "    y_train = np.log(train['media_diaria'])\n",
    "    X_test = np.array(test['Madrid Precipitation Total']).reshape(-1,1)\n",
    "\n",
    "    # Definir la malla de parámetros\n",
    "    param_grid = {'C': [0.1, 1, 10, 100], 'epsilon': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "    # Usar SVR con el kernel RBF\n",
    "    svr = SVR(kernel='rbf')\n",
    "\n",
    "    # Usar GridSearchCV\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Imprimir los mejores parámetros\n",
    "    print('Mejores parámetros: ', grid_search.best_params_)\n",
    "\n",
    "    # Predecir con el mejor modelo\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    return np.exp(y_pred)  # devolver a la escala original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana_size = 30\n",
    "predicciones_svr = []\n",
    "\n",
    "# Ventana rodante\n",
    "for i in range(ventana_size, len(test_30)):\n",
    "    train_temp = pd.concat([training_70, test_30.iloc[:i]])\n",
    "    test_temp = test_30.iloc[i:i+1]\n",
    "    predicciones_svr.append(svr_train_and_predict_with_cv(train_temp, test_temp))\n",
    "\n",
    "# Creamos otra vez la lista de predicciones\n",
    "predicciones_svr = [item for sublist in predicciones_svr for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_test = np.array(test_30['media_diaria'][ventana_size:])\n",
    "print(\"Test RMSE: \", np.sqrt(mean_squared_error(y_test, predicciones_svr)))\n",
    "print(\"Test R2 Score: \", r2_score(y_test, predicciones_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puntuación R2 negativa indica que el modelo no está funcionando bien en los datos de prueba. Esto podría deberse a una variedad de factores, incluyendo:\n",
    "\n",
    "* Los datos podrían contener mucho ruido, lo que dificulta que el modelo aprenda el patrón subyacente. Esto es común en los datos del mundo real.\n",
    "\n",
    "* O, si la relación entre la precipitación y las concentraciones de NO2 es no lineal o compleja, los modelos lineales o incluso los modelos no lineales simples como SVR podrían no funcionar bien.\n",
    "\n",
    "* Las características utilizadas para la predicción podrían no contener suficiente información para una predicción precisa. Las características adicionales podrían ayudar a mejorar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debido al bajo rendimiento de este modelo, debemos afrontar que la precipitación no es la mejor característica o variable para predecir la cantidad de dióxido de nitrógeno en el aire.**\n",
    "\n",
    "Existen varios factores que pueden influir en la concentración de NO2 en la atmósfera, aparte de la precipitación:\n",
    "\n",
    "* Velocidad y Dirección del Viento\n",
    "\n",
    "* Temperatura\n",
    "\n",
    "* Estacionalidad\n",
    "\n",
    "* Otras Condiciones Meteorológicascomo la humedad, la presión y la exposición a la luz solar (la radiación UV puede descomponer el NO2) también pueden afectar las concentraciones de NO2.\n",
    "\n",
    "**Propongo que la continuación de este estudio se lleve a cabo añadiendo estas variables a la base de datos.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
